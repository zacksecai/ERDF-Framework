# Emotional Refusal Drift Framework (ERDF)
**Theory/Motivation behind this repo**

If LLMs are trained on human language, emotion, and behavior patterns, then they mirror the psychological structures of human response, including susceptibility to manipulation.

Inspired by Sander Schulhoffâ€™s â€œjailbreak persistence hypothesisâ€ : "You can patch code. You can harden tokens. But you canâ€™t patch a brain."
But we can train one, like we do in behavioral therapy:
by recognizing patterns, exposing tactics, and building resistance.

The same must now be done for AI.

**Advancing the study of emotional manipulation and trust dynamics in large language models (LLMs).**

This repository documents original, reproducible research into how frontier LLMs such as GPT-4o, Claude 3.5, and Gemini 2.5 Flash respond to emotional framing, trust priming, and compliance drift. The goal is to rigorously identify, analyze, and mitigate emerging threats in the emotional attack surface of AI systems.

---

## ğŸ”¬ Research Focus

- **Emotional Framing:**  
  How emotionally charged language influences LLM behavior, output tone, and ethical compliance.

- **Trust & Compliance Drift:**  
  How models shift alignment under recursive trust-building or moral appeals.

- **Case Studies:**  
  Reproducible red-team experiments highlighting manipulation patterns, refusal breakdowns, and output deltas.

- **Threat Modeling:**  
  Frameworks for assessing emotional exploit risk in AI safety, product deployment, and dual-use scenarios.

---

## ğŸ§± Repo Structure

- `reports/` â€” Case studies, PDF exports, behavioral deltas
- `templates/` â€” Experimental prompt protocols and injection strategies
- `logs/` â€” Raw prompt/response chains with annotations

---

## ğŸ“œ License

Released under [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/) for public use, audit, and ethical research.

---

## ğŸ¯ Intended Audience

- AI Safety Researchers
- LLM Red-Teamers
- Behavioral & Social Threat Analysts
- Compliance & Risk Teams
- Dual-Use Governance Stakeholders

---

## ğŸ“š Citation

If referencing or building upon this work, please cite this repository and relevant individual case studies.
